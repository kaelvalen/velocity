# Velocity Configuration

# Logging
LOG_LEVEL=INFO

# Network Interrogation
MAX_PARALLEL_QUERIES=5
QUERY_TIMEOUT=10.0
USER_AGENT=Velocity/0.1.0

# Cognitive State
MAX_ITERATIONS=10
CONFIDENCE_THRESHOLD=0.7

# Hypothesis Evaluation
USE_GPU=false

# ============================================
# HYBRID MODE: LLM Synthesis (Optional)
# ============================================
# Enable LLM-powered natural language synthesis
# Velocity (NNEI) gathers facts, LLM formats them naturally
ENABLE_LLM=true

# LLM Provider: ollama, groq, openai, anthropic, none
LLM_PROVIDER=ollama

# Ollama Configuration (Local, privacy-first)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=mistral:7b

# Groq Configuration (Cloud, fast)
# GROQ_API_KEY=your_groq_key_here
# GROQ_MODEL=mixtral-8x7b-32768

# OpenAI Configuration
# OPENAI_API_KEY=your_openai_key_here
# OPENAI_MODEL=gpt-4o-mini

# Anthropic Configuration
# ANTHROPIC_API_KEY=your_anthropic_key_here
# ANTHROPIC_MODEL=claude-3-haiku-20240307

# LLM Synthesis Settings
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=500
LLM_STREAM=false
LLM_FALLBACK_TO_RAW=true

# Search Engines
DEFAULT_SEARCH_ENGINE=wikipedia
